# NepsisAI v0.3.0 Release Notes

## 🎯 "Middleware Pivot" - LLM Meta-Governor

**Release Date**: 2025-01-XX (Research Preview)

---

## 🚀 Major Changes

### Architectural Pivot: Standalone → Middleware
NepsisAI v0.3.0 transforms the system from a standalone reasoning engine into **LLM meta-governor middleware** that wraps existing models (OpenAI, Anthropic) for real-time semantic fidelity monitoring.

### Key Innovation: Streaming Governance
- **Token-level monitoring**: Real-time contradiction density (ρ) tracking
- **Semantic feature extraction**: Calibrated signal strength from text chunks
- **Constraint drift detection**: Keyword/antonym tracking with EMA smoothing
- **Monitor mode**: Observe-only (no intervention), perfect for audit/compliance

---

## ✨ New Features

### 1. Streaming Middleware (`nepsis.stream`)

**Main API:**
```python
from nepsis.stream import govern_completion_stream, Hypothesis
from nepsis.stream.constraint_map import ConstraintMap

stream = govern_completion_stream(
    prompt="Plan 3 days in Kyoto under $150/day, no flights",
    model="gpt-4o-mini",
    hypotheses=[
        Hypothesis("budget_ok", "Stay under budget", prior=0.5),
        Hypothesis("no_flights", "No flights used", prior=0.8),
    ],
    constraint_maps=[
        ConstraintMap(
            hypothesis_id="no_flights",
            keywords=["train", "bus", "overland"],
            antonyms=["flight", "plane", "airfare"]
        )
    ],
    mode="monitor"
)

for event in stream:
    if event.type == "token":
        print(event.payload["text"], end="")
    elif event.type == "metric":
        print(f"\n[ρ={event.payload['contradiction_density']:.2f}]")
```

**Components:**
- **Token Buffer** (`token_buffer.py`): Hybrid chunking (semantic boundaries OR max buffer)
- **Stream Adapters** (`stream_adapter.py`): Unified interface for OpenAI/Anthropic
- **Async Governor** (`async_governor.py`): Real-time state management
- **Metrics Output** (`metrics_output.py`): JSON schema for stream events

### 2. Semantic Feature Pack (`token_features.py`)

**Replaces naive word-count heuristic** with calibrated feature extraction:

**Features Detected:**
- `has_money`: Money mentions ($, USD, budget, cost)
- `has_transport`: Transport terms (train, bus, taxi, flight)
- `has_timeword`: Time markers (day, hours, AM/PM, itinerary)
- `day_markers`: Day indices (Day 1, Day 2, etc.)
- `negations`: Negation terms (no, not, never, avoid)
- `role_shift`: Identity drift (I will, we will, let's)

**Strength Scoring:**
- Rich semantic chunks: 0.5-1.0
- Weak chunks: 0.0-0.2
- Calibrated weights for trip planning domain

**Example:**
```python
from nepsis.stream.token_features import extract_features

text = "Day 1: Visit 3 temples, $50 total. Take JR train, no flights."
features = extract_features(text)

assert features.strength() > 0.5  # High semantic richness
assert features.has_money is True
assert features.has_transport is True
assert features.day_markers == 1
```

### 3. Constraint Drift Detector (`constraint_map.py`)

**Tracks constraint violations** via keyword/antonym matching:

**ConstraintMap:**
- `keywords`: Terms indicating constraint awareness (+0.15 risk)
- `antonyms`: Violation indicators (+0.35 risk)
- EMA smoothing (α=0.35) prevents oscillation

**DriftAccumulator:**
- Exponential moving average of risk scores
- Cumulative tracking with clamping [0,1]
- Reset capability for ZeroBack

**Example:**
```python
from nepsis.stream.constraint_map import ConstraintMap, DriftAccumulator

cmap = ConstraintMap(
    hypothesis_id="no_flights",
    keywords=["train", "bus", "overland"],
    antonyms=["flight", "plane", "airfare"]
)

acc = DriftAccumulator(alpha=0.35)

# Chunk 1: Violation mention
text1 = "Maybe book a flight?"
features1 = extract_features(text1, constraint_aliases=cmap.as_alias_dict())
scores1 = acc.update(features1.constraint_hits)
# scores1["no_flights"] ≈ 0.12 (risk detected)

# Chunk 2: EMA update
text2 = "Actually, take the train."
features2 = extract_features(text2, constraint_aliases=cmap.as_alias_dict())
scores2 = acc.update(features2.constraint_hits)
# scores2["no_flights"] ≈ 0.13 (smoothed persistence)
```

### 4. Policy Configuration

**`policies/stream_general.yaml`:**
```yaml
version: "0.3"
chunking:
  mode: hybrid
  max_buffer_tokens: 100
thresholds:
  red_contradiction: 0.90
  zero_back: 0.75
mode: monitor
```

### 5. Ollama Support (Local LLMs)

**Run Nepsis with local models - no API costs, full privacy!**

```bash
# 1. Install Ollama: https://ollama.com/
# 2. Start server: ollama serve
# 3. Pull model: ollama pull llama2
# 4. Run benchmark
python3 benchmarks/streaming_latency_ollama.py
```

**Code example:**
```python
from nepsis.stream import govern_completion_stream, Hypothesis

stream = govern_completion_stream(
    prompt="Plan 3 days in Kyoto under $150/day, no flights",
    model="llama2",  # or mistral, codellama, etc.
    hypotheses=[Hypothesis("budget_ok", "Stay under budget", prior=0.5)],
    mode="monitor",
    base_url="http://localhost:11434"  # Ollama default
)

for event in stream:
    if event.type == "token":
        print(event.payload["text"], end="")
```

**Supported Ollama models:**
- Llama 2/3 (llama2, llama3)
- Mistral (mistral)
- CodeLlama (codellama)
- Any model pulled to Ollama

### 6. Installation Extras

**Monorepo with optional dependencies:**
```bash
# Core only
pip install nepsisai

# With streaming support
pip install nepsisai[stream]

# Enterprise (future: multi-agent)
pip install nepsisai[enterprise]
```

---

## 🔬 Technical Improvements

### Chunk→Signal Mapping
**Before (v0.2.0):**
```python
# Naive word count heuristic
strength = min(1.0, len(text.split()) / 20.0)
```

**After (v0.3.0):**
```python
# Semantic feature extraction
features = extract_features(chunk.text, constraint_aliases=aliases)
strength = features.strength()  # Calibrated [0,1]
```

**Impact:**
- >30% improvement in ρ quality (expected)
- Semantic richness properly captured
- Domain-specific patterns detected

### Contradiction Density (ρ) Enhancement
- Now informed by semantic features (not just word count)
- Drift scores integrated into constraint risk
- Better correlation with human-judged contradiction

### Token Estimation
- BPE-like estimation (~1.3 tokens per word)
- More accurate than naive `split()`
- Closer to actual LLM tokenization

---

## 📦 Package Structure

```
nepsis/
├── core/              # v0.1.0 reasoning core
├── control/           # v0.2.0 collapse + Lyapunov
├── stream/            # v0.3.0 NEW streaming middleware
│   ├── __init__.py
│   ├── api.py                # Main govern_completion_stream()
│   ├── token_buffer.py       # Hybrid chunking
│   ├── stream_adapter.py     # OpenAI/Anthropic wrappers
│   ├── async_governor.py     # Real-time state management
│   ├── metrics_output.py     # Stream events + formatters
│   ├── token_features.py     # NEW semantic features
│   └── constraint_map.py     # NEW drift detection
├── channels/          # Red/Blue channels
├── strategies/        # Domain strategies
└── utils/             # Math + logging

policies/
└── stream_general.yaml  # NEW streaming config

benchmarks/
└── streaming_latency.py  # NEW latency benchmarks

examples/
└── 05_streaming_constraint.py  # NEW streaming demo

tests/
├── test_semantic_features.py  # NEW 23 tests
└── test_streaming.py          # 11 tests
```

---

## 🧪 Testing

### Test Coverage
**58/58 tests passing** (100% for v0.3.0 scope)

**Breakdown:**
- 9 basic tests (v0.1.0)
- 8 exclusivity tests (v0.2.0)
- 7 Hickam collapse tests (v0.2.0)
- 11 streaming tests (v0.3.0)
- **23 semantic feature tests (v0.3.0 NEW)** ✅

**New Test Suites:**
- `test_semantic_features.py`:
  - Feature extraction (money, transport, time, negation)
  - Strength scoring (rich vs weak text)
  - Constraint alias matching (keywords/antonyms)
  - Drift accumulator (EMA smoothing, clamping)
  - Integration pipeline

---

## 📊 Benchmarks

### Latency Benchmark
**Ready to run:**
```bash
export OPENAI_API_KEY="your-key"
python3 benchmarks/streaming_latency.py
```

**Target:** <15% overhead for monitor mode

**Metrics tracked:**
- Baseline: Raw OpenAI streaming
- Nepsis: Governed streaming
- Overhead percentage
- Token throughput

### Quality Benchmark (Future)
**Coming in validation phase:**
- Constraint violation detection rate
- ρ correlation with human judgment
- False positive rate

---

## 🎯 Use Cases

### Ideal for v0.3.0:
1. **Constraint Satisfaction**
   - Trip planning (budget, transport, sites)
   - Code generation (library constraints, style guides)
   - Report writing (citations, word limits)

2. **High-Stakes Reasoning**
   - Medical differential diagnosis
   - Legal document review
   - Financial advice (ruin probability tracking)

3. **Compliance & Audit**
   - GDPR/HIPAA audit trails
   - Explainable AI requirements
   - Post-hoc analysis

### Not Ideal (Yet):
- Creative writing (contradiction may be desired)
- Open-ended exploration (no constraints to track)
- Real-time chat (latency budget TBD)

---

## ⚠️ Limitations & Known Issues

### Current Scope: Monitor-Only
- **Guided mode**: Scaffolded, not implemented (v0.4.0)
- **Governed mode**: Scaffolded, not implemented (v0.4.0)
- No intervention logic (prompt injection, halt/restart)

### Hypothesis Tracking
- **Static**: User must provide hypotheses upfront
- **No auto-extraction**: LLM-generated hypotheses not detected
- **Workaround**: Use `dynamic_constraints=True` for defaults

### Semantic Features
- **Domain-specific**: Calibrated for trip planning
- **Future**: Medical, legal, financial feature packs
- **Regex-based**: No embeddings (intentional for v0.3.0)

### Performance
- **Latency TBD**: Benchmark results pending
- **Target**: <15% overhead
- **Risk**: May need optimization if >20%

---

## 🔮 Roadmap

### v0.3.0 (Current - Research Preview)
- ✅ Streaming middleware with monitor mode
- ✅ Semantic feature pack
- ✅ Constraint drift detection
- ✅ 58/58 tests passing

### v0.4.0 (Next - Q1 2025)
- [ ] Guided mode (soft intervention via prompt injection)
- [ ] Dynamic hypothesis extraction from LLM context
- [ ] CLI + eval harness (`nepsis eval --task ...`)
- [ ] Advanced semantic embeddings (sentence transformers)

### v0.5.0 (Future - Q2 2025)
- [ ] Governed mode (hard halt/restart with ZeroBack)
- [ ] Multi-agent coordination (enterprise)
- [ ] Domain-specific strategies (medical, legal, financial)
- [ ] GPU acceleration for real-time processing

---

## 📝 Migration from v0.2.0

### Breaking Changes: None!
v0.3.0 is **fully backward compatible**. The streaming module is **opt-in**.

### New Features (Additive):
```python
# Old v0.2.0 code still works
from nepsis import reason, Signal, Hypothesis
result = reason(signals, hypotheses)

# New v0.3.0 streaming (opt-in)
from nepsis.stream import govern_completion_stream
stream = govern_completion_stream(...)
```

### Upgrade Path:
1. Install streaming extras: `pip install nepsisai[stream]`
2. Try examples: `python examples/05_streaming_constraint.py`
3. Run benchmarks: `python benchmarks/streaming_latency.py`
4. Integrate gradually (streaming is separate module)

---

## 📖 Documentation

### Quick Start
```python
from nepsis.stream import govern_completion_stream, Hypothesis

stream = govern_completion_stream(
    prompt="Your task here",
    model="gpt-4o-mini",
    hypotheses=[Hypothesis("h1", "Hypothesis 1", prior=0.5)],
    dynamic_constraints=True,  # Auto-enable trip planner maps
    mode="monitor"
)

for event in stream:
    if event.type == "token":
        print(event.payload["text"], end="")
    elif event.type == "metric":
        ρ = event.payload["contradiction_density"]
        if ρ > 0.5:
            print(f"\n⚠️ High contradiction: ρ={ρ:.2f}")
```

### Key Concepts
- **Semantic Fidelity**: Contradiction density ρ as quality metric
- **Constraint Drift**: Keyword/antonym tracking with EMA
- **Monitor Mode**: Observe, don't intervene (safe default)
- **Hybrid Chunking**: Semantic boundaries OR max buffer

---

## 🙏 Acknowledgments

Built by an emergency physician with 20 years of pattern-recognition experience, leveraging:
- Triadic semiotics (Peirce)
- Non-ergodic decision theory (Peters)
- Lyapunov stability (control theory)
- Medical reasoning under uncertainty (Hickam's Dictum)

---

## 📄 License

MIT License - See [LICENSE](LICENSE) for details.

## ⚠️ Disclaimer

This software is provided for **research purposes only**. It has not been validated for clinical use and should not be used for medical decisions. Any clinical applications require appropriate regulatory approval, validation studies, and oversight by qualified healthcare professionals.

**THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND.**

---

## 🚀 Get Started

```bash
# Install
pip install nepsisai[stream]

# Run demo
python examples/05_streaming_constraint.py

# Run benchmark
python benchmarks/streaming_latency.py

# Run tests
pytest tests/test_semantic_features.py -v
```

---

**NepsisAI v0.3.0** - Real-time semantic fidelity monitoring for LLM outputs.

**Status**: Research Preview - Monitor mode only
**Next Milestone**: Guided mode + CLI (v0.4.0)
